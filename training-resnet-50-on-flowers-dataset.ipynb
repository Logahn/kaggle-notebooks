{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9900,"sourceType":"datasetVersion","datasetId":6209},{"sourceId":2431805,"sourceType":"datasetVersion","datasetId":8782}],"dockerImageVersionId":20479,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport numpy as np\nimport pandas as pd  # Potentially for labels if stored in a CSV file\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.python.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:57.079972Z","iopub.execute_input":"2024-06-24T01:36:57.080309Z","iopub.status.idle":"2024-06-24T01:36:59.385674Z","shell.execute_reply.started":"2024-06-24T01:36:57.080257Z","shell.execute_reply":"2024-06-24T01:36:59.384995Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Define paths and labels (assuming class folders within 'flowers' directory)\nbase_dir = '../input/flowers-recognition/'\ntrain_folder = os.path.join(base_dir, 'flowers')\nlabels = os.listdir(train_folder)  # Assuming class names correspond to folder names","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:59.387116Z","iopub.execute_input":"2024-06-24T01:36:59.387370Z","iopub.status.idle":"2024-06-24T01:36:59.396421Z","shell.execute_reply.started":"2024-06-24T01:36:59.387327Z","shell.execute_reply":"2024-06-24T01:36:59.395634Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Set image size and other training parameters\nimage_size = 224\nbatch_size = 32  # Experiment with different batch sizes\nepochs = 20  # Experiment with different numbers of epochs","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:59.397792Z","iopub.execute_input":"2024-06-24T01:36:59.398236Z","iopub.status.idle":"2024-06-24T01:36:59.402406Z","shell.execute_reply.started":"2024-06-24T01:36:59.397979Z","shell.execute_reply":"2024-06-24T01:36:59.401480Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train_datagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    rescale=1./255  # Normalize pixel values between 0 and 1\n    validation_split=0.2  # Use 20% of data for validation\n)\nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input, rescale=1./255)\n\n#","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:59.403673Z","iopub.execute_input":"2024-06-24T01:36:59.403892Z","iopub.status.idle":"2024-06-24T01:36:59.414268Z","shell.execute_reply.started":"2024-06-24T01:36:59.403857Z","shell.execute_reply":"2024-06-24T01:36:59.413166Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Data augmentation with normalization\ndatagen = ImageDataGenerator(\n    preprocessing_function=preprocess_input,\n    horizontal_flip=True,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    validation_split=0.2  # Use 20% of data for validation\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:59.415439Z","iopub.execute_input":"2024-06-24T01:36:59.415755Z","iopub.status.idle":"2024-06-24T01:36:59.424973Z","shell.execute_reply.started":"2024-06-24T01:36:59.415702Z","shell.execute_reply":"2024-06-24T01:36:59.424145Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Define training and validation data generators\ntrain_generator = train_datagen.flow_from_directory(\n    train_folder,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='training'\n)\nvalidation_generator = validation_datagen.flow_from_directory(\n    train_folder,\n    target_size=(image_size, image_size),\n    batch_size=batch_size,\n    class_mode='categorical',\n    subset='validation',\n    seed=42  # Set a seed for reproducibility during validation split\n)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:36:59.426158Z","iopub.execute_input":"2024-06-24T01:36:59.426474Z","iopub.status.idle":"2024-06-24T01:37:00.684924Z","shell.execute_reply.started":"2024-06-24T01:36:59.426424Z","shell.execute_reply":"2024-06-24T01:37:00.684162Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Found 4317 images belonging to 5 classes.\nFound 0 images belonging to 5 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define the model architecture\nresnet_weights_path = '../input/resnet50/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\ndef build_model():\n    model = Sequential()\n    # Load the pre-trained ResNet50 model with frozen layers\n    base_model = ResNet50(weights=resnet_weights_path, include_top=False, input_shape=(image_size, image_size, 3))\n    for layer in base_model.layers:\n        layer.trainable = False  # Freeze pre-trained layers\n\n    # Add custom layers for flower classification\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(1024, activation='relu'))  # Experiment with number of units and activation\n    model.add(Dropout(0.5))  # Experiment with dropout rate\n    model.add(Dense(len(labels), activation='softmax'))  # Final layer with output size matching number of classes\n    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:37:00.686535Z","iopub.execute_input":"2024-06-24T01:37:00.686785Z","iopub.status.idle":"2024-06-24T01:37:00.692927Z","shell.execute_reply.started":"2024-06-24T01:37:00.686743Z","shell.execute_reply":"2024-06-24T01:37:00.691984Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"model = build_model()\nmodel.summary()  # View model architecture\n\n# Early stopping and model checkpointing\nearly_stopper = EarlyStopping(monitor='val_loss', patience=5)\ncheckpointer = ModelCheckpoint(filepath='../working/best.hdf5',\n                               monitor='val_loss',\n                               save_best_only=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:37:00.694416Z","iopub.execute_input":"2024-06-24T01:37:00.694769Z","iopub.status.idle":"2024-06-24T01:37:12.000023Z","shell.execute_reply.started":"2024-06-24T01:37:00.694705Z","shell.execute_reply":"2024-06-24T01:37:11.998862Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.6/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n","output_type":"stream"},{"name":"stdout","text":"_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nresnet50 (Model)             (None, 7, 7, 2048)        23587712  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1024)              2098176   \n_________________________________________________________________\ndropout (Dropout)            (None, 1024)              0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 5125      \n=================================================================\nTotal params: 25,691,013\nTrainable params: 2,103,301\nNon-trainable params: 23,587,712\n_________________________________________________________________\n","output_type":"stream"}]},{"cell_type":"code","source":"# Train the model with callbacks\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch=train_generator.samples // batch_size,  # Ensure all data seen per epoch\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples // batch_size,  # Ensure all validation data used\n    epochs=epochs,\n    callbacks=[early_stopper, checkpointer]\n)\n# Load the best model based on validation loss\nmodel.load_weights('../working/best.hdf5')","metadata":{"execution":{"iopub.status.busy":"2024-06-24T01:37:12.001353Z","iopub.execute_input":"2024-06-24T01:37:12.001616Z","iopub.status.idle":"2024-06-24T05:29:28.770444Z","shell.execute_reply.started":"2024-06-24T01:37:12.001565Z","shell.execute_reply":"2024-06-24T05:29:28.715234Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Epoch 1/20\n133/134 [============================>.] - ETA: 5s - loss: 0.6568 - acc: 0.7874 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 689s 5s/step - loss: 0.6530 - acc: 0.7885\nEpoch 2/20\n133/134 [============================>.] - ETA: 5s - loss: 0.3843 - acc: 0.8596 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 682s 5s/step - loss: 0.3863 - acc: 0.8590\nEpoch 3/20\n133/134 [============================>.] - ETA: 5s - loss: 0.3462 - acc: 0.8772 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 690s 5s/step - loss: 0.3455 - acc: 0.8777\nEpoch 4/20\n133/134 [============================>.] - ETA: 5s - loss: 0.3208 - acc: 0.8890 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 697s 5s/step - loss: 0.3206 - acc: 0.8889\nEpoch 5/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2678 - acc: 0.9045 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 695s 5s/step - loss: 0.2673 - acc: 0.9048\nEpoch 6/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2653 - acc: 0.8989 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 692s 5s/step - loss: 0.2644 - acc: 0.8994\nEpoch 7/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2313 - acc: 0.9120 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 693s 5s/step - loss: 0.2313 - acc: 0.9122\nEpoch 8/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2237 - acc: 0.9170 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 697s 5s/step - loss: 0.2235 - acc: 0.9171\nEpoch 9/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2183 - acc: 0.9199 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 698s 5s/step - loss: 0.2172 - acc: 0.9202\nEpoch 10/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1788 - acc: 0.9336 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 696s 5s/step - loss: 0.1792 - acc: 0.9334\nEpoch 11/20\n133/134 [============================>.] - ETA: 5s - loss: 0.2096 - acc: 0.9250 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 695s 5s/step - loss: 0.2097 - acc: 0.9251\nEpoch 12/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1857 - acc: 0.9318 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 690s 5s/step - loss: 0.1848 - acc: 0.9321\nEpoch 13/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1972 - acc: 0.9299 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 692s 5s/step - loss: 0.1961 - acc: 0.9302\nEpoch 14/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1833 - acc: 0.9358 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 696s 5s/step - loss: 0.1823 - acc: 0.9363\nEpoch 15/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1891 - acc: 0.9297 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 694s 5s/step - loss: 0.1888 - acc: 0.9295\nEpoch 16/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1664 - acc: 0.9415 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 697s 5s/step - loss: 0.1658 - acc: 0.9417\nEpoch 17/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1420 - acc: 0.9478 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 696s 5s/step - loss: 0.1410 - acc: 0.9482\nEpoch 18/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1687 - acc: 0.9368 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 713s 5s/step - loss: 0.1682 - acc: 0.9366\nEpoch 19/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1577 - acc: 0.9410 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 715s 5s/step - loss: 0.1599 - acc: 0.9402\nEpoch 20/20\n133/134 [============================>.] - ETA: 5s - loss: 0.1284 - acc: 0.9521 WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,acc\nWARNING:tensorflow:Can save best model only with val_loss available, skipping.\n134/134 [==============================] - 718s 5s/step - loss: 0.1288 - acc: 0.9522\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)","\u001b[0;32m<ipython-input-9-61558af5e3ee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Load the best model based on validation loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../working/best.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name)\u001b[0m\n\u001b[1;32m   1510\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m         \u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m         \u001b[0msave_format\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'tf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0merrors_impl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLossError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/pywrap_tensorflow_internal.py\u001b[0m in \u001b[0;36mNewCheckpointReader\u001b[0;34m(filepattern)\u001b[0m\n\u001b[1;32m    324\u001b[0m   \u001b[0;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    325\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 326\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mCheckpointReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m \u001b[0mNewCheckpointReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tf_api_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train.NewCheckpointReader'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNotFoundError\u001b[0m: Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ../working/best.hdf5"],"ename":"NotFoundError","evalue":"Unsuccessful TensorSliceReader constructor: Failed to find any matching files for ../working/best.hdf5","output_type":"error"}]},{"cell_type":"code","source":"print(history.history.keys())","metadata":{"execution":{"iopub.status.busy":"2024-06-24T05:29:28.716100Z","iopub.status.idle":"2024-06-24T05:29:28.716649Z"},"trusted":true},"execution_count":null,"outputs":[]}]}